plot(x,y, main=paste("Gráfico de Dispersão entre as variáveis x e y", "\n"),xlab ="x", ylab = "y")
abline(lm(y~x), lty =2, lwd=2)#Adciona a reta tracejada
text(5,6, paste("y=", eval(expression(round(lm(y~x)$coef[[2]],2))), "x + ", eval(expression(round(lm(y~x)$coef[[1]],2)))))#Adciona a equação na posição (130,220)
t_x = sum(x)
t_x
n = length(x)
t_x = r*(sum(x)/n)
t_x
T_y = sum(y)
T_y = sum(y)
T_y
t_x = r*sum(x)/4
t_x
dt = data.table::data.table(bd_novo)
dt[1:50]
library(readr)
library(magrittr)
library(dplyr)
library(data.table)
bd <- read_csv("/Users/user/Documents/ESTATISTICA/AMOSTRAGEM_PRO_JOAO/artifratio.csv")
names(bd)
bd_novo <- bd %>%
dplyr::select(xbars,ybars)
names(bd_novo)
dt = data.table::data.table(bd_novo)
dt[1:50]
x = (dt$xbars)
y = (dt$ybars)
#Calculando a correlação e construíndo o gráfico de
#dispersão
library(ggplot2)
#Obtendo a correlação
cor(x,y)
r=sum(y)/sum(x)
r
#obtendo os coeficientes da reta de regressão
lm(y~x)$coef
plot(x,y, main=paste("Gráfico de Dispersão entre as variáveis x e y", "\n"),xlab ="x", ylab = "y")
abline(lm(y~x), lty =2, lwd=2)#Adciona a reta tracejada
text(5,6, paste("y=", eval(expression(round(lm(y~x)$coef[[2]],2))), "x + ", eval(expression(round(lm(y~x)$coef[[1]],2)))))#Adciona a equação na posição (130,220)
n = length(x)
n = length(x)
n
t_x = sum(x)
t_x
length(x)
knitr::opts_chunk$set(echo = TRUE)
# Link para:
url <-  " https://jornaldaparaiba.com.br/ "
url
# Ler o HTML da página da web
url <- c("https://www.jornaldaparaiba.com.br")
pagina <- read_html(url)
# Baixando e carregando o pacote
library( rvest )
library( xml2 )
library(shiny)
library(httr)
library(httr2)
# Ler o HTML da página da web
url <- c("https://www.jornaldaparaiba.com.br")
pagina <- read_html(url)
elementos <- pagina %>%
html_nodes("div.container a") #Aplicando as regras XPath
# html_nodes(".titles")
# Ler o HTML da página da web
url <- c("https://www.jornaldaparaiba.com.br")
pagina <- read_html(url)
elementos <- pagina %>%
html_nodes("div.container a")%>% #Aplicando as regras XPath
# html_nodes(".titles")
html_text2()
# Carregar o pacote rvest
library(rvest)
library(xml2)
library(shiny)
library(httr)
library(httr2)
# Ler o HTML da página da web
url <- "https://www.jornaldaparaiba.com.br"
pagina <- read_html(url)
dt <- html_nodes(pagina, "div.container a")
# Exibir o conteúdo dos elementos selecionados
cat("Conteúdo dos elementos selecionados:\n")
cat(html_text(dt), sep = "\n")
library(tidyverse)
library(tidytext)
library(quanteda)
library(dplyr)
library(rvest)
library(xml2)
texto <- (html_text(dt))
texto <- str_replace_all(texto,"\\(",")")
texto <- str_replace_all(texto, "\\)","")
texto <- str_replace_all(texto,"\n","")
texto <- str_replace_all(texto,"\t","")
texto
texto <- as.vector(texto)
text_df <- tibble(line=1:56, text= texto)
text_df
write.csv(text_df,file = "text_df.csv")
library(tidytext)
text_token <- text_df %>%
unnest_tokens(word, text)
text_token
#stopwords
library(quanteda)
stop_w <- tibble(word = stopwords(source = "stopwords-iso", language = "pt"))
#retirar do corpus as stopwords
tidy_text <- text_token %>%
anti_join(stop_w)
text_token %>%
count(word, sort = TRUE)
text_token %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(word, n)) %>%
slice(1:20) %>%
ggplot(aes(word, n)) +
geom_col() +
coord_flip() +
labs(x="")
#Transformando o data.frame em um corpus
corp <- corpus(texto)
summary(corp, 10)
#Tokens sem pontuação e sem sequência
toks <- tokens(corp, remove_punct = T, remove_numbers = T)
# Removendo as stopwords
toks_nostop <- tokens_select(toks, pattern = stopwords('pt'),
selection = 'remove')
# criando n-grams
toks_ngram <- tokens_ngrams(toks, n = 1:4)
toks_ngram
library(quanteda.textplots)
#criando uma DFM com as hashtags
dfmat_texto <- dfm(toks)
set.seed(132)
textplot_wordcloud(dfmat_texto, max_words = 100)
install.packages("plyr")
install.packages("ggplot2")
install.packages("wordcloud")
install.packages("plyr")
install.packages("wordcloud")
install.packages("wordcloud2")
install.packages("RColorBrewer")
install.packages("tm")
install.packages("SnowballC")
knitr::opts_chunk$set(echo = TRUE)
library(tm)
library(NLP)
#cname <- file.path("C:", "great-speeches")
#cname
#dir(cname)
docs <- VCorpus(DirSource(text_df))#Loading texts into R
library(tm)
library(NLP)
#cname <- file.path("C:", "great-speeches")
#cname
#dir(cname)
docs <- VCorpus(DirSource(texto))#Loading texts into R
texto)
texto
#cname <- file.path("C:", "great-speeches")
#cname
#dir(cname)
cname <- texto
dir(cnames)
#cname <- file.path("C:", "great-speeches")
#cname
#dir(cname)
cname <- texto
cname
dir(cnames)
#cname <- file.path("C:", "great-speeches")
#cname
#dir(cname)
cname <- as.character(texto)
dir(cnames)
docs <- VCorpus(DirSource(cname))#Loading texts into R
# Carregar o pacote rvest
library(rvest)
library(xml2)
library(shiny)
library(httr)
library(httr2)
# Ler o HTML da página da web
url <- "https://www.jornaldaparaiba.com.br"
pagina <- read_html(url)
dt <- html_nodes(pagina, "div.container a")
# Exibir o conteúdo dos elementos selecionados
cat("Conteúdo dos elementos selecionados:\n")
cat(html_text(dt), sep = "\n")
library(tidyverse)
library(tidytext)
library(quanteda)
library(dplyr)
library(rvest)
library(xml2)
texto <- (html_text(dt))
texto <- str_replace_all(texto,"\\(",")")
texto <- str_replace_all(texto, "\\)","")
texto <- str_replace_all(texto,"\n","")
texto <- str_replace_all(texto,"\t","")
texto
#texto <- as.vector(texto)
text_df <- tibble(line=1:56, text= texto)
text_df
#cname <- file.path("C:", "great-speeches")
#cname
#dir(cname)
cname <- text_df
dir(cnames)
docs <- VCorpus(DirSource(cname))#Loading texts into R
docs <- VCorpus(DirSource(text_df))#Loading texts into R
#cname <- file.path("C:", "great-speeches")
#cname
#dir(cname)
cname <- text_df
#dir(cnames)
docs <- VCorpus(cname)#Loading texts into R
#dir(cnames)
docs <- VCorpus(texto)#Loading texts into R
docs <- tm_map(text_df, removePunctuation)
docs <- tm_map(texto, removePunctuation)
docs <- tm_map(toks, removePunctuation)
docs <- tm_map(corp, removePunctuation)
docs <- tm_map(text_token, removePunctuation)
docs <- tm_map(dt, removePunctuation)
docs <- tm_map(html_texto(dt), removePunctuation)
docs <- tm_map(html_text(dt), removePunctuation)
dt <- as.factor(dt)
dt <- as.factor(as.cahacter(dt))
dt <- as.vector(as.cahacter(dt))
dt <- as.vector(as.character(dt))
docs <- tm_map(dt, removePunctuation)
dt <- as.vector(dt)
docs <- tm_map(dt, removePunctuation)
library(tm)
library(NLP)
#cname <- file.path("C:", "great-speeches")
#cname
#dir(cname)
#cname <- text_df
#dir(cnames)
docs <- VCorpus(dt)#Loading texts into R
docs <- VCorpus(DirSource(dt))#Loading texts into R
cname <- file.path("C:", "text_df")
cname
dir(cname)
docs <- VCorpus(DirSource(cname))#Loading texts into R
cname <- file.path("/Users/user/Documents/modelo2/Web_Scraping_In-cio:", "text_df")
cname
dir(cname)
docs <- VCorpus(DirSource(cname))#Loading texts into R
cname <- file.path("/Users/user/Documents/modelo2/Web_Scraping_In-cio/text_df")
cname
dir(cname)
docs <- VCorpus(DirSource(cname))#Loading texts into R
summary(docs)
cname <- file.path("/Users/user/Documents/modelo2/Web_Scraping_In-cio/text_df.csv")
cname
dir(cname)
docs <- VCorpus(DirSource(cname))#Loading texts into R
cname <- file.path("/Users/user/Documents/modelo2/Web_Scraping_In-cio/text_df.csv")
cname <- tibble(line=1:56, text= text_df)
dir(cname)
docs <- VCorpus(DirSource(cname))#Loading texts into R
cname <- tibble(line=1:56, text= texto)
dir(cname)
docs <- VCorpus(DirSource(cname))#Loading texts into R
text_df <- DataframeSource (text_df)
text_df <- as.DataframeSource (text_df)
text_df <- DataframeSource (texto)
text_df <- DataframeSource (text_token)
text_df <- DataframeSource (dt)
#Transformando o data.frame em um corpus
corp <- corpus(texto)
summary(corp, 10)
#Tokens sem pontuação e sem sequência
toks <- tokens(corp, remove_punct = T, remove_numbers = T)
library(tm)
library(NLP)
text_df <- DataframeSource (dt)
docs <- corp
summary(docs)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tn_map(docs, removewords, stopwords("pt"))
docs <- tm map (docs, removewords, c("irmãos", "irmãs"))
install.packages("Snowballc")
library (Snowballc)
docs <- tm map (docs, stemDocument)
dtm <- DocumentTermMatrix(docs)
dtm
tdm <- TermDocumentMatrix(docs)
tdm
#Frequência de ocorrência de cada palavra no corpus
freq <- colsums (as.matrix(dtm))
#Frequência de ocorrência de cada palavra no corpus
freq <- colsums (as.matrix(dtm))
??colsums
docs <- tm_map (docs, removewords, c("irmãos", "irmãs"))
install.packages("SnowballC")
library (SnowballC)
docs <- tm_map(docs, stemDocument)
install.packages("SnowballC")
library (SnowballC)
docs <- tm_map(docs, stemDocument)
docs <- tm_map (docs, stripwhitespace)
docs <- tm_map (docs, PlainTextDocument)
dtm <- DocumentTermMatrix(docs)
dtm
tdm <- TermDocumentMatrix(docs)
tdm
#Frequência de ocorrência de cada palavra no corpus
library(Matrix)
freq <- colsums (as.matrix(dtm))
#Frequência de ocorrência de cada palavra no corpus
library(MatrixModels)
freq <- colsums (as.matrix(dtm))
#Frequência de ocorrência de cada palavra no corpus
library(matrixStats)
freq <- colsums (as.matrix(dtm))
#Frequência de ocorrência de cada palavra no corpus
library(matrixStats)
freq <- colSums (as.matrix(dtm))
length(freq)
#para remover termos esparsos. Isso deixa 10% de espaço vazio.
dtms <-  removesparseTerms (dtm, 0.1)
??removesparseTerms
#para remover termos esparsos. Isso deixa 10% de espaço vazio.
library(tm)
dtms <-  removesparseTerms (dtm, 0.1)
#para remover termos esparsos. Isso deixa 10% de espaço vazio.
library(tm)
dtms <-  removeSparseTerms (dtm, 0.1)
dtms
freq <- colSums(as.matrix(dtms))
freq
#Matrix is organized according to the frequency of words
ord <- order(freq)
#Least Frequently occurring wors
freq[head(ord)]
#Most frequently ocorring words
freq[tail(ord)]
#Fine Grained Frequency usind sort command in decressing order
freq <- sort(colSums(as.matrix(dtms)), decreasing = TRUE)
head(freq, 14)
#Word which apperas more than 50 times
findFreqTerms(dtm, lowefreq = 50)
??findFreqTerms
#Word which apperas more than 50 times
findFreqTerms(dtm, lowefreq = 0)
#Word which apperas more than 50 times
findFreqTerms(dtm, lowfreq = 0)
#Fazendo o quadro de dados com as palavras com maior frequência
wf <- data.frame (word names (freq), freq-freq)
#Fazendo o quadro de dados com as palavras com maior frequência
wf <- data.frame ( names(freq), freq-freq)
head (wf)
#Fazendo o quadro de dados com as palavras com maior frequência
wf <- data.frame ( wordnames(freq), freq-freq)
#Fazendo o quadro de dados com as palavras com maior frequência
wf <- data.frame ( wordnames(freq), freq=freq)
#Fazendo o quadro de dados com as palavras com maior frequência
wf <- data.frame ( names(freq), freq=freq)
head (wf)
#Associação de país com outras palavras
findAssocs (dtms, "noticia", corlimit=0.90)
#Associação de governo com outras palavras
findAssocs (dtms, "governo", corlimit=0,90)
#Associação de país com outras palavras
findAssocs (dtms, "noticia", corlimit=0.90)
#Associação de governo com outras palavras
findAssocs (dtms, "governo", corlimit=0.90)
#Associação de pobre com outras palavras
findAssocs (dtms, "poor", corlimit=0.90)
#Associação de país com outras palavras
findAssocs (dtms, "paraiba", corlimit=0.90)
#Associação de governo com outras palavras
findAssocs (dtms, "joao pessoa", corlimit=0.90)
#Associação de pobre com outras palavras
findAssocs (dtms, "qual", corlimit=0.90)
#Associação de pessoas com outras palavras
Findassocs (tas, "pessoas", corlimit=0.90)
#Associação de pessoas com outras palavras
FindAssocs (tas, "pessoas", corlimit=0.90)
??findAssocs
library(tm)
#Associação de pessoas com outras palavras
FindAssocs (tas, "pessoas", corlimit=0.90)
install.packages("tm")
library(tm)
#Associação de pessoas com outras palavras
FindAssocs (tas, "pessoas", corlimit=0.90)
library(tm)
#Associação de pessoas com outras palavras
Findassocs (tas, "pessoas", corlimit=0.90)
library(tm)
#Associação de pessoas com outras palavras
FindAssocs (tas, "pessoas", corlimit=0.90)
exemplo_4_4 <- read.delim("~/Documents/ESTATISTICA/AMOSTRAGEM_PRO_JOAO/exemplo_4_4.txt")
View(exemplo_4_4)
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(magrittr)
library(dplyr)
library(data.table)
bd <- read.delim("~/Documents/ESTATISTICA/AMOSTRAGEM_PRO_JOAO/exemplo_4_4.txt")
names(bd)
#bd_novo <- bd %>%
# dplyr::select(xbars,ybars)
#names(bd_novo)
#dt = data.table::data.table(bd_novo)
#dt[1:50]
x = (bd$xbars)
y = (bd$ybars)
#Calculando a correlação e construíndo o gráfico de
#dispersão
library(ggplot2)
#Obtendo a correlação
cor(x,y)
names(bd)
library(readr)
library(magrittr)
library(dplyr)
library(data.table)
bd <- read.delim("~/Documents/ESTATISTICA/AMOSTRAGEM_PRO_JOAO/exemplo_4_4.txt")
names(bd)
#bd_novo <- bd %>%
# dplyr::select(xbars,ybars)
#names(bd_novo)
#dt = data.table::data.table(bd_novo)
#dt[1:50]
#Calculando a correlação e construíndo o gráfico de
#dispersão
library(ggplot2)
#Obtendo a correlação
cor(x,y)
#bd_novo <- bd %>%
# dplyr::select(xbars,ybars)
#names(bd_novo)
#dt = data.table::data.table(bd_novo)
#dt[1:50]
head(bd)
library(readr)
library(magrittr)
library(dplyr)
library(data.table)
bd <- read.delim("~/Documents/ESTATISTICA/AMOSTRAGEM_PRO_JOAO/exemplo_4_4.txt")
attach(bd)
names(bd)
#bd_novo <- bd %>%
# dplyr::select(xbars,ybars)
#names(bd_novo)
#dt = data.table::data.table(bd_novo)
#dt[1:50]
head(bd)
#Calculando a correlação e construíndo o gráfico de
#dispersão
library(ggplot2)
#Obtendo a correlação
cor(x,y)
library(readr)
library(magrittr)
library(dplyr)
library(data.table)
bd <- read.delim("~/Documents/ESTATISTICA/AMOSTRAGEM_PRO_JOAO/exemplo_4_4.txt")
attach(bd)
names(bd)
#bd_novo <- bd %>%
# dplyr::select(xbars,ybars)
#names(bd_novo)
#dt = data.table::data.table(bd_novo)
#dt[1:50]
head(bd)
x = (bd$x)
y = (bd$y)
#Calculando a correlação e construíndo o gráfico de
#dispersão
library(ggplot2)
#Obtendo a correlação
cor(x,y)
r=sum(y)/sum(x)
r
#obtendo os coeficientes da reta de regressão
lm(y~x)$coef
plot(x,y, main=paste("Gráfico de Dispersão entre as variáveis x e y", "\n"),xlab ="x", ylab = "y")
abline(lm(y~x), lty =2, lwd=2)#Adciona a reta tracejada
text(5,6, paste("y=", eval(expression(round(lm(y~x)$coef[[2]],2))), "x + ", eval(expression(round(lm(y~x)$coef[[1]],2)))))#Adciona a equação na posição (130,220)
n = length(x)
t_x = sum(x)
t_y = sum(y)
n = length(x)
t_x = sum(x)
t_y = sum(y)
tibble(t_x, t_y)
t_x = sum(x)
bchap = mean(y)/mean(x)
tchapyr = bchap*tx
t_x = sum(x)
bchap = mean(y)/mean(x)
tchapyr = bchap*t_x
t_srs = bchap*t_x
tibble(t_x, bchap, tchapyr, t_srs)
n=4
t_x = sum(x)
bchap = mean(y)/mean(x)
tchapyr = bchap*t_x
t_srs = sum(y)/n
tibble(t_x, bchap, tchapyr, t_srs)
q()
